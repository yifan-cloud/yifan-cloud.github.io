<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yifan Xu</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154209474-1"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-154209474-1');
		</script>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/yifan.jpg" alt="" /></span>
					<h4 id="logo"><a href="#">Yifan Xu</a></h4>
					<p>Master of Science, Robotics<br>University of Michigan</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about" class="active">About</a></li>
						<li><a href="#research">Research</a></li>
						<li><a href="#publications">Publications</a></li>
						<li><a href="#projects">Projects</a></li>
						<!-- <li><a href="#teaching">Teaching</a></li>
						<li><a href="#outreach">Outreach</a></li> -->
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="www.linkedin.com/in/yifan-xu-43876120b" class="icon brands fa-linkedin" target="_blank"><span class="label">Linkedin</span></a></li>
						<li><a href="https://github.com/yifan-cloud" class="icon brands fa-github" target="_blank"><span class="label">Github</span></a></li>
						<!-- <li><a href="https://scholar.google.com/citations?user=1HY3TXcAAAAJ&hl=en&authuser=1" class="icon solid fa-graduation-cap" target="_blank"><span class="label">Scholar</span></a></li> -->
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="about">
								<!-- <div class="image main" data-position="center">
									<img src="images/banner_cool.jpg" alt="" />
								</div> -->
								<div class="container">
									<header class="major">
										<h2>About</h2>
									</header>
									<p>
										I am currently a second year Master student in <a href="https://robotics.umich.edu/" target="_blank">Robotics</a> at the University of Michigan.
										My research advisor is <a href="https://robotics.umich.edu/profile/maani-ghaffari/" target="_blank">Prof. Maani Ghaffari</a> 
										and I am a research assistant and team leader of the <a href="https://curly.engin.umich.edu/" target="_blank">Computational Autonomy and Robotics Laboratory (CURLY)</a>. <br><br>
										I hold a B.S. degree in Robotics from Northeastern University(China).

										My research interests lies in SLAM, path planning and reinforcement learning. 
										<!-- I am a second-year Master's student in the <a href="https://robotics.umich.edu/" target="_blank">Robotics Institute</a> 
										at the <a href="https://umich.edu/" target="_blank">University of Michigan</a>. 
										I'm currently working in <a href="https://www.biped.solutions/" target="_blank">Biped Robotics Lab</a> and <a href="http://robots.engin.umich.edu/" target="_blank">the Perceptual Robotics Laboratory (PeRL)</a>,
										advised by <a href="http://ece.umich.edu/faculty/grizzle/" target="_blank">Prof. Jessy Grizzle</a>, <a href="http://robots.engin.umich.edu/~ryan/" target="_blank">Prof. Ryan Eustice</a>, and <a href="https://www.maanighaffari.com/" target="_blank">Dr. Maani Ghaffari</a>.
										I hold a B.S. degree in Mechanical Engineering from National Taiwan University.

										My research interest falls in perception and reasoning in robotics, including 3D geometric and semantic understanding, localization and mapping, and motion planning.</p> -->
																		
									<p>
										Email: yfx [at] umich [dot] edu					
									</p>

									<!-- <p><a href="CV_Justin.pdf" target="_blank">[CV]</a><a href="https://scholar.google.com/citations?user=1HY3TXcAAAAJ&hl=en&authuser=1" target="_blank">[Google Scholar]</a></p> -->
								
									<!-- <h3>News</h3>
									<div class="features">
										<article>
											November 16, 2021 <br>
											<p_news> I will be the Graduate Student Instructor of ROB530: Mobile Robotics for Winter 2022!</p_news>
										</article>
										<article>
											September 28, 2021 <br>
											<p_news> Check out our latest Mini Cheetah video.</p_news> <br>
											<iframe width="560" height="315" src="https://www.youtube.com/embed/oVbP-Y8xT_E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
										</article>
										<article>
											September 13, 2021 <br>
											<p_news> Our paper "Legged Robot State Estimation using Invariant Kalman Filtering and Learned Contact Events" is accepted to 2021 Conference on Robot Learning (CoRL)!</p_news>
										</article>
										<article>
											May 30, 2021 <br>
											<p_news> Our paper "A New Framework for Registration of Semantic Point Clouds from Stereo and RGB-D Cameras" is published in 2021 IEEE International Conference on Robotics and Automation (ICRA)!</p_news>
										</article>
									</div> -->
							</div>
							</section>

						<!-- Two -->
							<section id="research">
								<div class="container">
									<h3>Research</h3>
									<p>
									</p>
									<div class="features">
											<article>
												<!-- <iframe width="340" height="200" src="https://www.youtube.com/embed/oVbP-Y8xT_E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
										
												<a href="images/contact_estimation.png" class="image"><img src="images/contact_estimation.png" alt="" /></a>
												<div class="inner">
													<h4>Legged Robot State Estimation using Invariant Kalman Filtering and Learned Contact Events</h4>
													<p>
														We developed a learning-based contact estimator for legged robots that bypasses the need for physical sensors and takes multi-modal proprioceptive sensory data as input. The trained network can estimate contact events on different terrains and is deployed along with a contact-aided invariant extended Kalman filter (InEKF). This network allows legged robot state estimators to benefit from foot contact information without having a physical contact sensor. The proposed state estimation pipeline runs real-time with an NVIDIA AGX Jetson on an MIT Mini Cheetah robot. All codes are open-sourced to the public.

														<br>
														
														<a href="https://openreview.net/forum?id=yt3tDB67lc5" target="_blank">[Paper]</a><br>
														<a href="https://github.com/UMich-CURLY/deep-contact-estimator" target="_blank">[Deep-Contact-Estimator]</a><br>
														<a href="https://github.com/UMich-CURLY/cheetah_inekf_realtime" target="_blank">[Invariant-EKF for Mini Cheetah]</a>
														
													</p>
													
												</div>
												<!-- <a href="images/cvo_traj.png" class="image"><img src="images/cvo_traj.png" alt="" /></a> -->
											</article>
											<article>
												<a href="images/cvo.png" class="image"><img src="images/cvo.png" alt="" /></a>
												
												<div class="inner">
													<h4>Continuous Visual Odometry</h4>
													<p>
														We develop a fundamentally novel formulation of the sensor registration problem, Continuous Sensor Registration, that is continuous and models the action of an arbitrary Lie group on any smooth manifold. 
														The continuity is achieved by treating the output of a given sensor as a function that lives on a reproducing kernel Hilbert space (RKHS). The outputs of two sensors are registered by integrating the flow in the Lie algebra and minimizing the norm of the difference between the two functions.
														
														Continuous Visual Odometry (CVO) is a special case of the Continuous Sensor Registration that takes in images from a commonly used camera, either stereo or monocular, as input and estimate the trajectory by accumulating the transformation matrix found between each frame.
														<a href="https://github.com/MaaniGhaffari/cvo-rgbd" target="_blank">[Code]</a>
													</p>
													
												</div>
												<!-- <a href="images/cvo_traj.png" class="image"><img src="images/cvo_traj.png" alt="" /></a> -->
											</article>
											<article>
													<a href="images/cassie_gazebo.png" class="image"><img src="images/cassie_gazebo.png" alt="" /></a>
													<div class="inner">
														<h4>Simulation of Bipedal Robot with Camera and Lidar Sensor</h4>
														<p>
															We built up a simulation environment in Gazebo and Mujoco that allowed us to test control and perception systems for the bipedal robot, Cassie Blue. This project aims to help increase the variety and amount of environments in which we can test Cassieâ€™s performance. 
														</p>
													</div>
											</article>
											<article>
												<a href="images/colonoscopy_3.png" class="image"><img src="images/colonoscopy_3.png" alt="" /></a>
												<div class="inner">
													<h4>Automated Colonoscopy Assistance</h4>
													<p>
														In colonoscopy procedures, the examining device can accidentally pierce the colon, which is known as perforation and has an incident rate of 0.2%. The goal of this project is to prevent the tip of the colonoscope from contacting the intestinal wall to reduce the perforation rate. We used the video feed from the colonoscopy device and implemented a computer vision algorithm to track the center of the colon in real-time and applied a PID controller to achieve the goal.
													</p>
												</div>
												<!-- <a href="images/colonoscopy_2.png" class="image"><img src="images/colonoscopy_2.png" alt="" /></a> -->
											</article>
											<!-- <article>
												<a href="#" class="image"><img src="images/pic03.jpg" alt="" /></a>
												<div class="inner">
													<h4>Snapped dark matter in the wild</h4>
													<p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer adipiscing ornare amet.</p>
												</div>
											</article> -->
										</div>
								</div>
							</section>

						<!-- Three -->
							<section id="publications">
								<div class="container">
									<h3>Publications</h3>
									<h4>Conference Papers</h4>
									<ul>
										<p1><li><b>Tzu-Yuan Lin</b>, Ray Zhang, Justin Yu, and Maani Ghaffari. <b>"Legged Robot State Estimation using Invariant Kalman Filtering and Learned Contact Events."</b> In 5th Annual Conference on Robot Learning (CoRL), 2021. &nbsp; <a href="https://openreview.net/forum?id=yt3tDB67lc5" target="_blank">[Paper]</a><a href="https://github.com/UMich-CURLY/deep-contact-estimator" target="_blank">[Code]</a><a href="https://youtu.be/oVbP-Y8xT_E" target="_blank">[Video]</a></li></p1>
										<p1><li>Ray Zhang, <b>Tzu-Yuan Lin</b>, Chien Erh Lin, Steven A Parkison, William Clark, Jessy W Grizzle, Ryan M Eustice, and Maani Ghaffari. <b> "A New Framework for Registration of Semantic Point Clouds from Stereo and RGB-D Cameras"</b> In 2021 IEEE International Conference on Robotics and Automation (ICRA), 2021, pp. 12214-12221. &nbsp; <a href="https://ieeexplore.ieee.org/document/9561929" target="_blank">[Paper]</a><a href="https://github.com/UMich-CURLY/unified_cvo" target="_blank">[Code]</a><a href="https://youtu.be/M3XZOAWyu04" target="_blank">[Video]</a></li></p1>
										
									</ul>
									<h4>Preprints</h4>
									<ul>
										<p1><li>Xi Lin, Dingyi Sun, <b>Tzu-Yuan Lin</b>, Ryan M. Eustice, and Maani Ghaffari. <b>"A Keyframe-based Continuous Visual SLAM for RGB-D Cameras via Nonparametric Joint Geometric and Appearance Representation."</b> Submitted to 2020 Conference on Computer Vision and Pattern Recognition (CVPR). Seattle, USA, 2020.
											<a href="https://arxiv.org/abs/1912.01064" target="_blank">[arXiv]</a></li></p1>
										<p1><li><b>Tzu-Yuan Lin</b>, William Clark, Ryan M. Eustice, Jessy W. Grizzle, Anthony Bloch, and Maani Ghaffari. <b>"Adaptive Continuous Visual Odometry from RGB-D Images."</b> Submitted to 2020 International Conference on Robotics and Automation (ICRA). IEEE, Paris, France, 2020.
											<a href="https://arxiv.org/abs/1910.00713" target="_blank">[arXiv]</a></li></p1>
									</ul>
									
									
								</div>
							</section>

						<!-- Four -->
							<section id="projects">
								<div class="container">
									<h3>Projects</h3>
									<div class="features">
										<article>
											<a href="images/image_caption_generator.png" class="image"><img src="images/image_caption_generator.png" alt="" /></a>
											<div class="inner">
												<h4>Image Caption Generator with Simple Semantic Segmentation</h4>
												<p>
													Utilized a pre-trained ImageNet as the encoder, and a Long-Short Term Memory (LSTM) net with attention module as the decoder in PyTorch that can automatically generate properly formed English sentences of the inputted images. 
													Implemented a simple semantic segmentation algorithm by highlighting the attention layer used to generate the English sentence.
												</p>
											</div>
										</article>
										<article>
											<a href="images/DVO_with_BA.JPG" class="image"><img src="images/DVO_with_BA.JPG" alt="" /></a>
											<div class="inner">
												<h4>Direct Visual Odometry with Pose Graph Optimization and LoopClosure</h4>
												<p>
													Implemented an offline direct visual odometry algorithm with pose-graph optimization to track a robotâ€™s position using RGB-D camera image as input.
												</p>
											</div>
										</article>
										<article>
												<a href="images/botlab.png"  class="image"><img src="images/botlab.png" alt="" /></a>
												<div class="inner">
													<h4>Simultaneous Localization and Mapping (SLAM) Robot with Particle Filter and Path Planning</h4>
													<p>
														Implemented a particle filter based simultaneous localization and mapping (SLAM) system and A* path planning algorithm
														for a robot with 2D LiDAR to explore and escape an arbitrarily-configured maze.
													</p>
												</div>
											</article>
										<article>
											<a href="images/project-selfdriving.png"  class="image"><img src="images/project-selfdriving.png" alt="" /></a>
											<div class="inner">
												<h4>Vehicle Classification and Localization</h4>
												<p>Utilized OpenCV for image preprocessing and TensorFlow for DenseNet deep learning to classify 22 different types of vehicle from a video game and localize them by point cloud data.</p>
											</div>
										</article>
										<article>
											<h4>6 DOF Robot Arm with a 3D Block Detector and Color Segmentation</h4>
											<iframe width="560" height="315" src="https://www.youtube.com/embed/vHC6HfZUM6k" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
											
											<p>
												We developed a working system capable of autonomously identifying and manipulating colored blocks with a 3-link robotic manipulator. 
												The tasks we accomplished with the robot arm includes: Stacked the blocks in a specific color order, moved and mirrored the position of the blocks in one side of the plane to the other side, and built a pyramid with the wooden blocks.
											</p>
											
										</article>
									</div>
									<p>

									</p>
								</div>
							</section>

						<!-- Five -->
							<section id="teaching">
								<div class="container">
									<h3>Teaching</h3>
									<h4>ROB 530: Mobile Robotics -- Graduate Student Instructor</h4>
									Robotics Institute, University of Michigan, Winter 2020 & Winter 2022
									<br>
									<p>
										Theory and application of probabilistic techniques for autonomous mobile robotics. 
										Topics include Bayesian filtering; stochastic representations of the environment; 
										motion and sensor models for mobile robots; 
										algorithms for mapping, localization; 
										application to autonomous marine, ground, and air vehicles.
									</p>
									<h4>ME 2001: Engineering Mathematics -- Teaching Assistant</h4>
									Mechanical Engineering, National Taiwan University, Fall 2017 & Spring 2017
									<br>
									<p>
										Topics include Linear Algebra, Differential Equations, Laplace Transform, Fourier Series, and Real Analysis.
									</p>

									<h4>ME 1003: Engineering Graphics  -- Teaching Assistant</h4>
									Mechanical Engineering, National Taiwan University, Spring 2017
									<br>
									<p>
										This course talks about concepts in engineering drawing and teaches students a 3D drawing software - Autodesk Inventor.
									</p>	

									<h4>ME 2004: Machine Design Theory -- Teaching Assistant</h4>
									Mechanical Engineering, National Taiwan University, Fall 2017
									<br>
									<br>

									<h4>ME 2005: Thermodynamics -- Teaching Assistant</h4>
									Mechanical Engineering, National Taiwan University, Fall 2017
									<br>

									


								</div>
							</section>

						<!-- Six -->
						<section id="outreach">
								<div class="container">
									<h3>Outreach</h3>
									<div class="features">
										<article>
											<a href="images/outreach-discover.jpg" class="image"><img src="images/outreach-discover.jpg" alt="" /></a>
											<div class="inner">
												<h4>UM Discover Engineering</h4>
												<p>Helped design and organize a robotics coding activity for a two day camp for local high school students. Guided students in the workshop through the robotics line following and grasping task. The camp focused on increasing their interest in STEM, as well as over-viewing its academic and career paths.</a></p>
											</div>
										</article>
											
										<article>
											<a href="images/outreach-kidzone.JPG" class="image"><img src="images/outreach-kidzone.JPG" alt="" /></a>
											<div class="inner">
												<h4>Ann Arbor Summer Festival KidZone</h4>
												<p>Demonstrated current robotics sensors and explained their usage and theories to local families.</a></p>
											</div>
										</article>
										</div>	
								</div>
							</section>

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>